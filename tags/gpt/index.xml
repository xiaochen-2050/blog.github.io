<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>GPT on Xiao.chen</title>
    <link>https://blog.wisekee.com/tags/gpt/</link>
    <description>Recent content in GPT on Xiao.chen</description>
    <generator>Hugo -- gohugo.io</generator>
    <copyright>Copyright © 2008–2020, Xiao.chen; all rights reserved.</copyright>
    <lastBuildDate>Wed, 20 Nov 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://blog.wisekee.com/tags/gpt/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Setup the Dify and vllm in AWS G4dn instance</title>
      <link>https://blog.wisekee.com/post/dify-vllm-ec2/</link>
      <pubDate>Wed, 20 Nov 2024 00:00:00 +0000</pubDate>
      
      <guid>https://blog.wisekee.com/post/dify-vllm-ec2/</guid>
      <description>
        
          
            The first step launch the AWS ec2 type G4dn-xlarge 1# initialization the default ebs volume 2sudo file -s /dev/nvme2n1 3lsblk -f 4mkfs -t xfs /dev/nvme2n1 5mount /dev/nvme2n1 /mnt 6 7# persistent the mount info to `/etc/fstab` 8# view the UUID 9blkid 10 11# write the information 12echo &amp;#34;UID=xxxxx-3047-437a-81f0-xxxxx /mnt xfs defaults,nofail 0 2&amp;#34; &amp;gt;&amp;gt; /etc/fstab Extends the root ebs volume 1# modify the ebs volume size in aws console 2# extend the partition 3growpart /dev/nvme0n1 1 4# extend thf filesystem 5resize2fs /dev/nvme0n1p1 Install the docker-ce 1# Add Docker&amp;#39;s official GPG key: 2sudo apt-get update 3sudo apt-get install ca-certificates curl 4sudo install -m 0755 -d /etc/apt/keyrings 5sudo curl -fsSL https://download.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Open source text to image and image LLM</title>
      <link>https://blog.wisekee.com/post/text_to_image_llm/</link>
      <pubDate>Thu, 10 Oct 2024 00:00:00 +0000</pubDate>
      
      <guid>https://blog.wisekee.com/post/text_to_image_llm/</guid>
      <description>
        
          
            Large models related to image processing OmniGen: Unified Image Generation. FLUX.1 minimal inference code to run image generation Llama OCRAbout Document to Markdown OCR library with Llama 3.2 vision deepfaceAbout A Lightweight Face Recognition and Facial Attribute Analysis (Age, Gender, Emotion and Race) Library for Python PIXART-αFast Training of Diffusion Transformer for Photorealistic Text-to-Image Synthesis LTX-VideoDiT-based video generation model Hugging face playground: play ground 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Getting started LLM for workshop</title>
      <link>https://blog.wisekee.com/post/llm-getting-started/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://blog.wisekee.com/post/llm-getting-started/</guid>
      <description>
        
          
            How to use the LLMs Prompt Engineering Retrieval Augmented Generation (RAG) Fine-tuning Training your own Foundation Model(FM) from scratch Vector databases Milvus Database for AI. Store Vectors, Images, Texts, Videos, etc. Use with LLMs/LangChain deeplake Knowledge Referred to as &amp;ldquo;prompts&amp;rdquo;. Designing a prompt is essentially how you “program” a large language model model Plugins can be “eyes and ears” for language models Using commands to instruct the model what you want to achieve, such as &amp;ldquo;Write&amp;rdquo;, &amp;ldquo;Classify&amp;rdquo;, &amp;ldquo;Summarize&amp;rdquo;, &amp;ldquo;Translate&amp;rdquo;, &amp;ldquo;Order&amp;rdquo; Foundation model (FM) – An AI model with a large number of parameters and trained on a massive amount of diverse data.
          
          
        
      </description>
    </item>
    
  </channel>
</rss>
